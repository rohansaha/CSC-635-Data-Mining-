{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Data.csv\"\n",
    "data = pd.read_csv(filename)\n",
    "X = data[[data.columns[1], data.columns[2]]]\n",
    "Y = data[data.columns[-1]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size= 0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.64713932\n",
      "Iteration 2, loss = 0.64427722\n",
      "Iteration 3, loss = 0.64014591\n",
      "Iteration 4, loss = 0.63531808\n",
      "Iteration 5, loss = 0.63037575\n",
      "Iteration 6, loss = 0.62517624\n",
      "Iteration 7, loss = 0.62017166\n",
      "Iteration 8, loss = 0.61521638\n",
      "Iteration 9, loss = 0.61037427\n",
      "Iteration 10, loss = 0.60559281\n",
      "Iteration 11, loss = 0.60103227\n",
      "Iteration 12, loss = 0.59658290\n",
      "Iteration 13, loss = 0.59218442\n",
      "Iteration 14, loss = 0.58805118\n",
      "Iteration 15, loss = 0.58400038\n",
      "Iteration 16, loss = 0.58006219\n",
      "Iteration 17, loss = 0.57617288\n",
      "Iteration 18, loss = 0.57248475\n",
      "Iteration 19, loss = 0.56893206\n",
      "Iteration 20, loss = 0.56537547\n",
      "Iteration 21, loss = 0.56191725\n",
      "Iteration 22, loss = 0.55863108\n",
      "Iteration 23, loss = 0.55529508\n",
      "Iteration 24, loss = 0.55218796\n",
      "Iteration 25, loss = 0.54910313\n",
      "Iteration 26, loss = 0.54605199\n",
      "Iteration 27, loss = 0.54317285\n",
      "Iteration 28, loss = 0.54038282\n",
      "Iteration 29, loss = 0.53757036\n",
      "Iteration 30, loss = 0.53492331\n",
      "Iteration 31, loss = 0.53233319\n",
      "Iteration 32, loss = 0.52985678\n",
      "Iteration 33, loss = 0.52743096\n",
      "Iteration 34, loss = 0.52508718\n",
      "Iteration 35, loss = 0.52279204\n",
      "Iteration 36, loss = 0.52060150\n",
      "Iteration 37, loss = 0.51841125\n",
      "Iteration 38, loss = 0.51631085\n",
      "Iteration 39, loss = 0.51416886\n",
      "Iteration 40, loss = 0.51224437\n",
      "Iteration 41, loss = 0.51029398\n",
      "Iteration 42, loss = 0.50833023\n",
      "Iteration 43, loss = 0.50651392\n",
      "Iteration 44, loss = 0.50469306\n",
      "Iteration 45, loss = 0.50296955\n",
      "Iteration 46, loss = 0.50124991\n",
      "Iteration 47, loss = 0.49963340\n",
      "Iteration 48, loss = 0.49799617\n",
      "Iteration 49, loss = 0.49641333\n",
      "Iteration 50, loss = 0.49495209\n",
      "Iteration 51, loss = 0.49340933\n",
      "Iteration 52, loss = 0.49197344\n",
      "Iteration 53, loss = 0.49058636\n",
      "Iteration 54, loss = 0.48921381\n",
      "Iteration 55, loss = 0.48782777\n",
      "Iteration 56, loss = 0.48648716\n",
      "Iteration 57, loss = 0.48522164\n",
      "Iteration 58, loss = 0.48397680\n",
      "Iteration 59, loss = 0.48275675\n",
      "Iteration 60, loss = 0.48162195\n",
      "Iteration 61, loss = 0.48042291\n",
      "Iteration 62, loss = 0.47932455\n",
      "Iteration 63, loss = 0.47822652\n",
      "Iteration 64, loss = 0.47713335\n",
      "Iteration 65, loss = 0.47611295\n",
      "Iteration 66, loss = 0.47508371\n",
      "Iteration 67, loss = 0.47411761\n",
      "Iteration 68, loss = 0.47313301\n",
      "Iteration 69, loss = 0.47218715\n",
      "Iteration 70, loss = 0.47127321\n",
      "Iteration 71, loss = 0.47037283\n",
      "Iteration 72, loss = 0.46948638\n",
      "Iteration 73, loss = 0.46862659\n",
      "Iteration 74, loss = 0.46778481\n",
      "Iteration 75, loss = 0.46697241\n",
      "Iteration 76, loss = 0.46619421\n",
      "Iteration 77, loss = 0.46539544\n",
      "Iteration 78, loss = 0.46466931\n",
      "Iteration 79, loss = 0.46392936\n",
      "Iteration 80, loss = 0.46316664\n",
      "Iteration 81, loss = 0.46247401\n",
      "Iteration 82, loss = 0.46179751\n",
      "Iteration 83, loss = 0.46111816\n",
      "Iteration 84, loss = 0.46046283\n",
      "Iteration 85, loss = 0.45981446\n",
      "Iteration 86, loss = 0.45919678\n",
      "Iteration 87, loss = 0.45856671\n",
      "Iteration 88, loss = 0.45796742\n",
      "Iteration 89, loss = 0.45737596\n",
      "Iteration 90, loss = 0.45680366\n",
      "Iteration 91, loss = 0.45623337\n",
      "Iteration 92, loss = 0.45570440\n",
      "Iteration 93, loss = 0.45516403\n",
      "Iteration 94, loss = 0.45461065\n",
      "Iteration 95, loss = 0.45411125\n",
      "Iteration 96, loss = 0.45359168\n",
      "Iteration 97, loss = 0.45311117\n",
      "Iteration 98, loss = 0.45264369\n",
      "Iteration 99, loss = 0.45216591\n",
      "Iteration 100, loss = 0.45171150\n",
      "Accuracy -> 0.8288043478260869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(5,2,1), max_iter=100, alpha=0.0001,\n",
    "         solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print('Accuracy ->',accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multioutput target data is not supported with label binarization",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-35c90b2c5566>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    971\u001b[0m         \"\"\"\n\u001b[0;32m    972\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[1;32m--> 973\u001b[1;33m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    329\u001b[0m                              hidden_layer_sizes)\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_type_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'multioutput'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_type_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             raise ValueError(\"Multioutput target data is not supported with \"\n\u001b[0m\u001b[0;32m    279\u001b[0m                              \"label binarization\")\n\u001b[0;32m    280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Multioutput target data is not supported with label binarization"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
